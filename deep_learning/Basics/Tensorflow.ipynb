{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[-3.35990334]\n",
      " [-2.98146868]\n",
      " [-0.50485754]\n",
      " [ 1.67346978]\n",
      " [ 1.59832478]]\n"
     ]
    }
   ],
   "source": [
    "v = tf.placeholder(tf.float32)\n",
    "A = tf.placeholder(tf.float32, shape=(5,5), name='A')\n",
    "\n",
    "w = tf.matmul(A, v)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    output = session.run(w, feed_dict={A: np.random.randn(5, 5), v: np.random.randn(5, 1)})\n",
    "    \n",
    "    print(type(output))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[-0.39176068  0.31372842]\n",
      " [-0.33116049 -0.23026608]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(tf.random_normal((2, 2)))\n",
    "t = tf.Variable(0)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    out = session.run(init)\n",
    "    print(out)\n",
    "    \n",
    "    print(x.eval())\n",
    "    print(t.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0, cost = 67.990, u = 7.700\n",
      "i = 1, cost = 11.508, u = 2.780\n",
      "i = 2, cost = 2.471, u = 0.812\n",
      "i = 3, cost = 1.025, u = 0.025\n",
      "i = 4, cost = 0.794, u = -0.290\n",
      "i = 5, cost = 0.757, u = -0.416\n",
      "i = 6, cost = 0.751, u = -0.466\n",
      "i = 7, cost = 0.750, u = -0.487\n",
      "i = 8, cost = 0.750, u = -0.495\n",
      "i = 9, cost = 0.750, u = -0.498\n",
      "i = 10, cost = 0.750, u = -0.499\n",
      "i = 11, cost = 0.750, u = -0.500\n",
      "i = 12, cost = 0.750, u = -0.500\n",
      "i = 13, cost = 0.750, u = -0.500\n",
      "i = 14, cost = 0.750, u = -0.500\n"
     ]
    }
   ],
   "source": [
    "u = tf.Variable(20.0)\n",
    "cost = u*u + u + 1\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(0.3).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    for i in range(15):\n",
    "        session.run(train_op)\n",
    "        print(\"i = {}, cost = {:.3f}, u = {:.3f}\".format(i, cost.eval(), u.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Hidden layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_normalized_data():\n",
    "    df = pd.read_csv('../datasets/mnist/train.csv')\n",
    "    data = df.as_matrix().astype(np.float32)\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:, 1:]\n",
    "    mu = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    np.place(std, std == 0, 1)\n",
    "    X = (X - mu) / std # normalize the data\n",
    "    Y = data[:, 0]\n",
    "    return X, Y\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N, 10))\n",
    "    for i in range(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = get_normalized_data()\n",
    "Xtrain = X[:-1000,]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:,]\n",
    "Ytest  = Y[-1000:]\n",
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)\n",
    "\n",
    "max_iter = 200\n",
    "print_period = 20\n",
    "\n",
    "lr = 0.00004\n",
    "reg = 0.01\n",
    "\n",
    "N, D = Xtrain.shape\n",
    "batch_sz = 500\n",
    "n_batches = N // batch_sz\n",
    "\n",
    "# add an extra layer just for fun\n",
    "M1 = 300\n",
    "M2 = 100\n",
    "K = 10\n",
    "W1_init = np.random.randn(D, M1) / 28\n",
    "b1_init = np.zeros(M1)\n",
    "W2_init = np.random.randn(M1, M2) / np.sqrt(M1)\n",
    "b2_init = np.zeros(M2)\n",
    "W3_init = np.random.randn(M2, K) / np.sqrt(M2)\n",
    "b3_init = np.zeros(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variables and expressions\n",
    "X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "T = tf.placeholder(tf.float32, shape=(None, K), name='T')\n",
    "\n",
    "W1 = tf.Variable(W1_init.astype(np.float32))\n",
    "b1 = tf.Variable(b1_init.astype(np.float32))\n",
    "W2 = tf.Variable(W2_init.astype(np.float32))\n",
    "b2 = tf.Variable(b2_init.astype(np.float32))\n",
    "W3 = tf.Variable(W3_init.astype(np.float32))\n",
    "b3 = tf.Variable(b3_init.astype(np.float32))\n",
    "\n",
    "# define the model\n",
    "Z1 = tf.nn.relu( tf.matmul(X, W1)+b1 )\n",
    "Z2 = tf.nn.relu( tf.matmul(Z1, W2)+b2 )\n",
    "Yish = tf.matmul(Z2, W3) + b3 # remember, the cost function does the softmaxing! weird, right?\n",
    "\n",
    "# softmax_cross_entropy_with_logits take in the \"logits\"\n",
    "# if you wanted to know the actual output of the neural net,\n",
    "# you could pass \"Yish\" into tf.nn.softmax(logits)\n",
    "cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=Yish, labels=T))\n",
    "\n",
    "# we choose the optimizer but don't implement the algorithm ourselves\n",
    "# let's go with RMSprop, since we just learned about it.\n",
    "# it includes momentum!\n",
    "train_op = tf.train.RMSPropOptimizer(lr, decay=0.99, momentum=0.9).minimize(cost)\n",
    "\n",
    "# we'll use this to calculate the error rate\n",
    "predict_op = tf.argmax(Yish, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost / err at iteration i=0, j=0: 2355.775 / 0.898\n",
      "Cost / err at iteration i=20, j=0: 146.480 / 0.033\n",
      "Cost / err at iteration i=40, j=0: 208.420 / 0.027\n",
      "Cost / err at iteration i=60, j=0: 226.193 / 0.020\n",
      "Cost / err at iteration i=80, j=0: 276.242 / 0.023\n",
      "Cost / err at iteration i=100, j=0: 280.043 / 0.020\n",
      "Cost / err at iteration i=120, j=0: 286.510 / 0.021\n",
      "Cost / err at iteration i=140, j=0: 287.023 / 0.020\n",
      "Cost / err at iteration i=160, j=0: 290.276 / 0.021\n",
      "Cost / err at iteration i=180, j=0: 293.962 / 0.020\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGJFJREFUeJzt3WuMXPd53/HfMzN7n8PLkrtnqSXppcKdMSQ1kWtCUOMi\ncKIklpsiUt8YNFBbCAwrgNXESQMUVt60LyogL9q0NVALUG3XMupaUBynForYqaMGCIrWclaOEllS\nyN2IokiK3F1eJO6Fe5t5+mLO7M7euLeZPTPnfD/AYs78z2UejjTnN+f8/3OOubsAAOmUibsAAEB8\nCAEASDFCAABSjBAAgBQjBAAgxQgBAEgxQgAAUowQAIAUIwQAIMVycRewlaNHj/rQ0FDcZQBAS3n1\n1Vevu3vfVss1fQgMDQ1pZGQk7jIAoKWY2cXtLMfpIABIMUIAAFKMEACAFCMEACDFCAEASDFCAABS\njBAAgBRLbAg8/3/f0Ut/817cZQBAU0tsCPzRq5f0RyOX4i4DAJpaYkOg0B/o/PhU3GUAQFNLbggM\nBBq/Pa8PZhfjLgUAmlZiQ6AYBpKk8xMcDQDAZhIbAoWBSgicu0YIAMBmEhsC9xzsVL4jR78AANxF\nYkPAzDQc5gkBALiLxIaAVOkXOHdtSu4edykA0JQSHQKFMNCt2UVdn16IuxQAaEqJDoFi1DnMKSEA\n2FiiQ6AQMkIIAO4m0SFwNN+uw91tGuW3AgCwoUSHgJmpEHUOAwDWS3QISJV+gfPj04wQAoANJD4E\nCmGg6fklvffBXNylAEDTSXwILI8Q4pQQAKyT+BAo9DNMFAA2k/gQONjdpvBAh84RAgCwTuJDQKr0\nC3AkAADrpSIEimGg0fFplcqMEAKAWqkIgUIYaH6prHdvzsZdCgA0lXSEANcQAoANpSIEhvvzkhgm\nCgBrpSIEejpyOtHbxQghAFgjFSEgVTqHOR0EAKulJgSGw0BvT85oYakcdykA0DRSEwLFMNBS2fXO\njZm4SwGAppGaEOAGMwCw3pYhYGYnzOwvzOxNM3vDzL4Ytfea2Q/NbDR6PFyzztNmNmZm58zsEzXt\nHzWz16N5XzYza8w/a717+3qUzRj9AgBQYztHAkuSfs/d75P0sKSnzOw+SV+S9LK7D0t6OXquaN5Z\nSfdLelTSV8wsG23rWUmflzQc/T1ax3/LXXW2ZTV0pJsjAQCosWUIuPtVd/9JND0l6S1Jg5Iek/R8\ntNjzkh6Pph+T9IK7z7v7BUljkh4ys2OSDrj7j7xyh5dv1qyzL7iGEACstqM+ATMbkvQRSa9ICt39\najTrmqQwmh6UdKlmtctR22A0vbZ93xTCQBdvzmpusbSfLwsATWvbIWBmeUl/LOl33P127bzom33d\nrs5mZk+a2YiZjUxOTtZrsyoOBHKXxiam67ZNAGhl2woBM2tTJQC+5e7fjZrHo1M8ih4novYrkk7U\nrH48arsSTa9tX8fdn3P3M+5+pq+vb7v/li0xQggAVtvO6CCT9DVJb7n7H9bMeknSE9H0E5K+V9N+\n1sw6zOyUKh3AP45OHd02s4ejbX62Zp19MXSkW+3ZDP0CABDJbWOZj0n6jKTXzey1qO33Jf2BpBfN\n7HOSLkr6lCS5+xtm9qKkN1UZWfSUu1dPwn9B0jckdUn6fvS3b3LZjO7t6+EaQgAQ2TIE3P3/SNps\nPP8jm6zzjKRnNmgfkfTATgqst+JAoJF3bsVZAgA0jdT8YriqEAa68v4dTc0txl0KAMQudSFQDKs3\nmGGEEACkLwS4yxgALEtdCAwe6lJXW5ZhogCgFIZAJmMqhHmNThACAJC6EJAqncPnrtEnAACpDIHi\nQKDr0/O6MT0fdykAEKtUhkCBEUIAICn1IUC/AIB0S2UIhAc6dKAzRwgASL1UhoCZqTjADWYAIJUh\nIFVHCE2pcisEAEin1IZAcSDQ7bkljd9mhBCA9EptCAz3RzeY4ZQQgBRLbQgUwrwkaZQQAJBiqQ2B\nI/kOHc13cA0hAKmW2hCQpOJAnhFCAFIt1SFQCAOdH59WucwIIQDplPoQuLNY0uVbd+IuBQBikfoQ\nkLh8BID0SnkIVEYIMUwUQFqlOgSCzjYNHuriSABAaqU6BKTK0QDDRAGkFSEQBnp7ckZLpXLcpQDA\nviMEwkALpbLeuTEbdykAsO9SHwLFAUYIAUiv1IfA6f68zES/AIBUSn0IdLZlNXSkhyMBAKmU+hCQ\npOH+PL8VAJBKhIAq/QIXb8xqbrEUdykAsK8IAVVGCJXKrrcnZ+IuBQD2FSEgRggBSC9CQNLQkR61\nZY1+AQCpQwhIas9ldOpoj84zTBRAyhACkUIY6PwEIQAgXQiBSDEMdOnmHc3ML8VdCgDsmy1DwMy+\nbmYTZvbTmrZ/Y2ZXzOy16O+f1Mx72szGzOycmX2ipv2jZvZ6NO/LZmb1/+fsXiHqHB6dmI65EgDY\nP9s5EviGpEc3aP8P7v5g9PenkmRm90k6K+n+aJ2vmFk2Wv5ZSZ+XNBz9bbTN2BSrdxmjXwBAimwZ\nAu7+l5JubnN7j0l6wd3n3f2CpDFJD5nZMUkH3P1H7u6Svinp8d0W3QgnervVkcswQghAquylT+C3\nzOxvo9NFh6O2QUmXapa5HLUNRtNr25tGNmMaDvP8VgBAquw2BJ6VdK+kByVdlfTv61aRJDN70sxG\nzGxkcnKynpu+q0IYEAIAUmVXIeDu4+5ecveypP8i6aFo1hVJJ2oWPR61XYmm17Zvtv3n3P2Mu5/p\n6+vbTYm7UgwDjd+e1/uzC/v2mgAQp12FQHSOv+qfSaqOHHpJ0lkz6zCzU6p0AP/Y3a9Kum1mD0ej\ngj4r6Xt7qLshCsuXj2CEEIB0yG21gJl9W9LHJR01s8uS/rWkj5vZg5Jc0juSflOS3P0NM3tR0puS\nliQ95e7VS3N+QZWRRl2Svh/9NZVCNELo3PiUHjrVG3M1ANB4W4aAu396g+av3WX5ZyQ9s0H7iKQH\ndlTdPrvnYKfyHTmN0i8AICX4xXANM1MhzHOrSQCpQQisURyojBCq/JwBAJKNEFijEAa6Nbuoyen5\nuEsBgIYjBNYoLF8+ghFCAJKPEFhjOQToHAaQAoTAGkfz7ertaScEAKQCIbDG8gghQgBAChACGyiG\ngc5fY4QQgOQjBDYwHAaaWSjpyvt34i4FABqKENhAsXqXMa4hBCDhCIENFPpXriEEAElGCGzgYHeb\nBg50cqtJAIlHCGximBFCAFKAENhEMQw0NjGtUpkRQgCSixDYRGEg0PxSWe/enI27FABoGEJgE8Xq\nDWboFwCQYITAJobDvCSuIQQg2QiBTXS353Sit4vOYQCJRgjcRfXyEQCQVITAXRTCQBeuz2hhqRx3\nKQDQEITAXRQHAi2VXReuz8RdCgA0BCFwF9UbzNAvACCpCIG7uLevR9mM0S8AILEIgbvoyGU1dKSb\nIwEAiUUIbKE4EGiUEACQUITAFgphoIs3Z3VnoRR3KQBQd4TAFophIHdpbIIbzABIHkJgC8OMEAKQ\nYITAFoaOdKs9m+EaQgASiRDYQi6b0c/05wkBAIlECGxDMczzWwEAiUQIbENhINB7H8zp9txi3KUA\nQF0RAttQ6K90DvN7AQBJQwhsQ3GgepcxhokCSBZCYBsGD3Wpuz1L5zCAxCEEtiGTMQ2HASEAIHG2\nDAEz+7qZTZjZT2vaes3sh2Y2Gj0erpn3tJmNmdk5M/tETftHzez1aN6Xzczq/89pnGLIMFEAybOd\nI4FvSHp0TduXJL3s7sOSXo6ey8zuk3RW0v3ROl8xs2y0zrOSPi9pOPpbu82mVggDXZ9e0PXp+bhL\nAYC62TIE3P0vJd1c0/yYpOej6eclPV7T/oK7z7v7BUljkh4ys2OSDrj7j9zdJX2zZp2WUL3BDEcD\nAJJkt30CobtfjaavSQqj6UFJl2qWuxy1DUbTa9tbRnWE0Og4I4QAJMeeO4ajb/Zeh1qWmdmTZjZi\nZiOTk5P13PSu9QcdOtjVxoXkACTKbkNgPDrFo+hxImq/IulEzXLHo7Yr0fTa9g25+3Pufsbdz/T1\n9e2yxPoyMxXDgMtHAEiU3YbAS5KeiKafkPS9mvazZtZhZqdU6QD+cXTq6LaZPRyNCvpszTotYzjM\n69z4lCoHPwDQ+rYzRPTbkv6fpKKZXTazz0n6A0m/Ymajkn45ei53f0PSi5LelPQDSU+5e/WWXF+Q\n9FVVOov/XtL36/xvabjiQKCpuSVduz0XdykAUBe5rRZw909vMuuRTZZ/RtIzG7SPSHpgR9U1mZUR\nQtM6drAr5moAYO/4xfAOLIcA/QIAEoIQ2IHennb1BR2MEAKQGITADhW4fASABCEEdqgQBhodn1a5\nzAghAK2PENihYhjozmJJl2/dibsUANgzQmCHCtUbzHBKCEACEAI7NNyfl8SF5AAkAyGwQ0FnmwYP\ndekcw0QBJAAhsAuMEAKQFITALhQGAr09OaPFUjnuUgBgTwiBXSiGgRZKZV28MRN3KQCwJ4TALlQv\nH3HuGjeYAdDaCIFdON2fV8YYJgqg9RECu9DZltWHjvRwITkALY8Q2KVCmNf5CUIAQGsjBHapGAZ6\n5/qM5hZLWy8MAE2KENilwkCgskt/P0nnMIDWRQjs0spdxjglBKB1EQK7NHSkR21ZY5gogJZGCOxS\ney6je4/mNcqRAIAWRgjsQWEg4LcCAFoaIbAHxTCvy7fuaHp+Ke5SAGBXCIE9GI46hzklBKBVEQJ7\nUGSEEIAWRwjswYnebnW2ZXR+nBFCAFoTIbAH2YxpuD/gSABAyyIE9qgQBtxqEkDLIgT2qBDmNTE1\nr1szC3GXAgA7RgjsUWGAzmEArYsQ2KPlEUITdA4DaD2EwB4dO9ipoCPHDWYAtCRCYI/MjMtHAGhZ\nhEAdFMK8zo9Pyd3jLgUAdoQQqINCGOj92UVNTs3HXQoA7AghUAcrl4+gcxhAayEE6qA6TJR+AQCt\nZk8hYGbvmNnrZvaamY1Ebb1m9kMzG40eD9cs/7SZjZnZOTP7xF6LbxZH8x060tPOCCEALaceRwK/\n6O4PuvuZ6PmXJL3s7sOSXo6ey8zuk3RW0v2SHpX0FTPL1uH1m8JwmOdIAEDLacTpoMckPR9NPy/p\n8Zr2F9x93t0vSBqT9FADXj8WxTDQKCOEALSYvYaAS/pzM3vVzJ6M2kJ3vxpNX5MURtODki7VrHs5\nalvHzJ40sxEzG5mcnNxjifujMBBoZqGkK+/fibsUANi2vYbAP3b3ByV9UtJTZvYLtTO98rV4x1+N\n3f05dz/j7mf6+vr2WOL+4AYzAFrRnkLA3a9EjxOS/kSV0zvjZnZMkqLHiWjxK5JO1Kx+PGpLhOqt\nJs9dY5gogNax6xAwsx4zC6rTkn5V0k8lvSTpiWixJyR9L5p+SdJZM+sws1OShiX9eLev32wOdrVp\n4EAnRwIAWkpuD+uGkv7EzKrb+e/u/gMz+ytJL5rZ5yRdlPQpSXL3N8zsRUlvSlqS9JS7l/ZUfZMp\nDHCDGQCtZdch4O5vS/q5DdpvSHpkk3WekfTMbl+z2RXDvH709g2Vyq5sxuIuBwC2xC+G66gQBlpY\nKuvijZm4SwGAbSEE6qjACCEALYYQqKPhMC+JEUIAWgchUEfd7Tmd7O3mSABAyyAE6qwQBoQAgJZB\nCNRZcSCvC9dnNL+UqNGvABKKEKizQhhoqey6cJ0RQgCaHyFQZ4Xly0dwSghA8yME6uzevh5lM0a/\nAICWQAjUWUcuq1NHe7jfMICWQAg0QJERQgBaBCHQAMNhXu/enNXswlLcpQBoIe6uUtm1sFTW3GJp\nX+5UuJeriGITxTCQuzQ2Ma2fPX4o7nKQIO6upXJlR7FYKqtUrjxfKrmWyuWofaP5NdPlcrR8dVtl\nlcvR9te81vL0qiKqDzXzfd3sDdrXL796u5UlSmVX2SuvX/bKdKns0XMtt5XLK/N3s2wpmu/uKpdr\nlq3OL7vcq/Ws335p1Xo1y1eXjeZV/z1bbbdSy+r/3uf+7aPqyDX2VuyEQAMUBlZGCBECzcHdNTk1\nr3dvzurSrVldn1pQafkD6Sqt+TAvf2jLlQ979UNbcl/+tla7cynVTm/woa/uFNauv+FOulRe3kFX\n2xejHX+pzD2sqzImZTMmM1PGpIyZMmayqD0TtVfnZy1aNrOy7Nr1MtH86rKV7VTac5lM9Hq127fl\nOirrrn6tbPW11rVH262pc7N5jUYINMCHervVnstodILO4f00u7CkSzfv6NLNWb0b/VWnL92a1dxi\necttWPRhrN0ZrPoQ13z41+8Q1uwc1uxMstGOJpfNqCNX2WY2ep7L2PJjNmNqy1Yec5moLWtqi3ZC\nGy+bUS5rNW3rl61MR8tG05XlM8rW7Gw22+/Utkf3EZFtNl8bb2/Vpm39sss75cz6HfTaHTvqgxBo\ngFw2o9N9eX4rUGflsmt8ak7v3li9g6/83dH16flVy/e0Z3XySI/u7evRx4t9OtnbreO93TrZ262+\noEO5zMrOnJ0L0ooQaJBCmNcrF27GXUbLmZpb1KWbd9bt5C/dnNXlW3e0UFr5Np8x6Z5DXTrZ261H\nPtyvk0e6dSLayZ/s7dbh7jZ26sAWCIEGKQwE+h+vvacP7izqYFdb3OU0jaVSWVc/mFvzLX5lh39r\ndnHV8gc6czp5pFsfPhboV+4Pl3fwJ3u7dc+hLrVlGeAG7AUh0CDF6PIRo+NTOjPUG3M1u+Puml8q\na2Z+SbMLJc0sLGlmvqTZ2seFkmbnax/vvsz0/NKqzs1cxjR4uPJt/pP/4NiqnfyJw9062E2AAo1E\nCDTIyl3GpmMNgam5RY1NTOvC9RlNzVV20rPz1R36mp14zbzq404Go/S0Z9Xdkas8tufU05HVoe52\nDR6OnrdnFXS26Xi00z/R261jBzuV49s8EBtCoEEGD3Wppz27b78cfn92QaMT0xodn9boxJTGoulr\nt+fWLZsxqacjp572nLo7spXH9qz6g051H8mubo8ee6o79zU7+epjZy6rTIbz70CrIQQaJJMxnQ6D\nuo4QcnfdmFnQ6Pi0xiamanb606tGxnS1ZXW6P6+f/5kjOh3mNdwf6N6+Hh3ubld3e1YduQwdpgAk\nEQINVQzzevmtiR2v5+6amJpf/lY/OjGtsWi6tuM035HT6f68frHYp+FoZ3+6P6/BQ118KwewLYRA\nAxXCQC+OXNb16XkdzXesm18uu9774I7GJqaXT99Ud/pTcyvXHTrY1aZCmNejDxzTcH9ep/vzGg7z\nGjjQyTd6AHtCCDRQMbp8xN9dndKJ3qXlUzfVc/ZjE9OaXVi5DeXRfLtO9+f1+IODGg6jnX1/oKP5\ndnb2ABqCEGig6jDRz3z9lVUXhgoPdGi4P9CnzpxYdRqnt6c9pkoBpBUh0EB9QYd++5dOa3ahFH2z\nr+zs+fEYgGZBCDSQmelf/mox7jIAYFP8SgcAUowQAIAUIwQAIMUIAQBIMUIAAFKMEACAFCMEACDF\nCAEASDFz38FdQ2JgZpOSLu5y9aOSrtexnFbH+7GC92I13o8VSXkvPuTufVst1PQhsBdmNuLuZ+Ku\no1nwfqzgvViN92NF2t4LTgcBQIoRAgCQYkkPgefiLqDJ8H6s4L1YjfdjRarei0T3CQAA7i7pRwIA\ngLtIZAiY2aNmds7MxszsS3HXEyczO2Fmf2Fmb5rZG2b2xbhripuZZc3sr83sf8ZdS9zM7JCZfcfM\n/s7M3jKzfxR3TXEys9+NPic/NbNvm1ln3DU1WuJCwMyykv6zpE9Kuk/Sp83svniritWSpN9z9/sk\nPSzpqZS/H5L0RUlvxV1Ek/hPkn7g7h+W9HNK8ftiZoOSflvSGXd/QFJW0tl4q2q8xIWApIckjbn7\n2+6+IOkFSY/FXFNs3P2qu/8kmp5S5UM+GG9V8TGz45J+TdJX464lbmZ2UNIvSPqaJLn7gru/H29V\nsctJ6jKznKRuSe/FXE/DJTEEBiVdqnl+WSne6dUysyFJH5H0SryVxOo/SvpXkspxF9IETkmalPRf\no9NjXzWznriLiou7X5H07yS9K+mqpA/c/X/FW1XjJTEEsAEzy0v6Y0m/4+63464nDmb2TyVNuPur\ncdfSJHKS/qGkZ939I5JmJKW2D83MDqty1uCUpHsk9ZjZP4+3qsZLYghckXSi5vnxqC21zKxNlQD4\nlrt/N+56YvQxSb9uZu+ocprwl8zsv8VbUqwuS7rs7tUjw++oEgpp9cuSLrj7pLsvSvqupJ+PuaaG\nS2II/JWkYTM7ZWbtqnTsvBRzTbExM1PlnO9b7v6HcdcTJ3d/2t2Pu/uQKv9f/G93T/w3vc24+zVJ\nl8ysGDU9IunNGEuK27uSHjaz7uhz84hS0FGei7uAenP3JTP7F5L+TJXe/a+7+xsxlxWnj0n6jKTX\nzey1qO333f1PY6wJzeO3JH0r+sL0tqTfiLme2Lj7K2b2HUk/UWVU3V8rBb8e5hfDAJBiSTwdBADY\nJkIAAFKMEACAFCMEACDFCAEASDFCAABSjBAAgBQjBAAgxf4/cSr7aeOQ/o0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44ad346400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs = []\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        for j in range(n_batches):\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "            session.run(train_op, feed_dict={X: Xbatch, T: Ybatch})\n",
    "            if i%print_period==0 and j==0:\n",
    "                test_cost = session.run(cost, feed_dict={X: Xtest, T: Ytest_ind})\n",
    "                prediction = session.run(predict_op, feed_dict={X: Xtest})\n",
    "                err = error_rate(prediction, Ytest)\n",
    "                print(\"Cost / err at iteration i={}, j={}: {:.3f} / {:.3f}\".format(i, j, test_cost, err))\n",
    "                costs.append(test_cost)\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add regularization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
