{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(M1, M2):\n",
    "    return np.random.randn(M1, M2) * np.sqrt(2.0 / M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self, M1, M2, f):\n",
    "        \"\"\"\n",
    "        Params\n",
    "        -------\n",
    "        M1 : int\n",
    "            Incoming dimensions\n",
    "        M2 : int\n",
    "            Outgoing dimensions\n",
    "        f : func\n",
    "            Activation function\n",
    "        \"\"\"\n",
    "        self.M1 = M1\n",
    "        self.M2 = M2\n",
    "        self.f = f\n",
    "        W = init_weight(M1, M2)\n",
    "        b = np.zeros(M2)\n",
    "        self.W = theano.shared(W)\n",
    "        self.b = theano.shared(b)\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.f == T.nnet.relu:\n",
    "            return self.f(X.dot(self.W)+self.b, alpha=0.1)\n",
    "        return self.f(X.dot(self.W)+self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ANN(object):\n",
    "    def __init__(self, hidden_layer_sizes):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "\n",
    "    def fit(self, X, Y, activation=T.nnet.relu, \n",
    "            learning_rate=1e-3, mu=0.0, reg=0, \n",
    "            epochs=100, batch_sz=None, print_period=100, show_fig=True):\n",
    "        X = X.astype(np.float32)\n",
    "        Y = Y.astype(np.int32)\n",
    "\n",
    "        # initialize hidden layers\n",
    "        N, D = X.shape\n",
    "        self.layers = []\n",
    "        M1 = D\n",
    "        for M2 in self.hidden_layer_sizes:\n",
    "            h = HiddenLayer(M1, M2, activation)\n",
    "            self.layers.append(h)\n",
    "            M1 = M2\n",
    "        \n",
    "        # final layer\n",
    "        K = len(set(Y))\n",
    "        # print(\"K:\", K)\n",
    "        h = HiddenLayer(M1, K, T.nnet.softmax)\n",
    "        self.layers.append(h)\n",
    "\n",
    "        if batch_sz is None:\n",
    "            batch_sz = N\n",
    "\n",
    "        # collect params for later use\n",
    "        self.params = []\n",
    "        for h in self.layers:\n",
    "            self.params += h.params\n",
    "\n",
    "        # for momentum\n",
    "        dparams = [theano.shared(np.zeros_like(p.get_value())) for p in self.params]\n",
    "\n",
    "        # set up theano functions and variables\n",
    "        thX = T.matrix('X')\n",
    "        thY = T.ivector('Y')\n",
    "        p_y_given_x = self.forward(thX)\n",
    "\n",
    "        rcost = reg * T.mean([(p*p).sum() for p in self.params])\n",
    "        cost = - T.mean(T.log(p_y_given_x[T.arange(thY.shape[0]), thY])) #+ rcost\n",
    "        grads = T.grad(cost, self.params)\n",
    "        prediction = T.argmax(p_y_given_x, axis=1)\n",
    "\n",
    "        # momentum only\n",
    "        updates = [\n",
    "            (p, p + mu*dp - learning_rate*g) for p, dp, g in zip(self.params, dparams, grads)\n",
    "        ] + [\n",
    "            (dp, mu*dp - learning_rate*g) for dp, g in zip(dparams, grads)\n",
    "        ]\n",
    "\n",
    "        train_op = theano.function(\n",
    "            inputs=[thX, thY],\n",
    "            outputs=[cost, prediction],\n",
    "            updates=updates,\n",
    "        )\n",
    "\n",
    "        self.predict_op = theano.function(\n",
    "            inputs=[thX],\n",
    "            outputs=prediction,\n",
    "        )\n",
    "\n",
    "        n_batches = N // batch_sz\n",
    "        costs = []\n",
    "        for i in range(epochs):\n",
    "            if n_batches > 1:\n",
    "                X, Y = shuffle(X, Y)\n",
    "            for j in range(n_batches):\n",
    "                Xbatch = X[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "                Ybatch = Y[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "\n",
    "                c, p = train_op(Xbatch, Ybatch)\n",
    "                costs.append(c)\n",
    "                if (j+1) % print_period == 0:\n",
    "                    print(\"i:\", i, \"j:\", j, \"nb:\", n_batches, \"cost:\", c)\n",
    "        \n",
    "        if show_fig:\n",
    "            plt.plot(costs)\n",
    "            plt.show()\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = X\n",
    "        for h in self.layers:\n",
    "            out = h.forward(out)\n",
    "        return out\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        P = self.predict_op(X)\n",
    "        return np.mean(Y == P)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.predict_op(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
