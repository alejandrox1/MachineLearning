{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When there i a single input variable the method is referered to as simple linear regression.\n",
    "$$ y = b_0 + b_1 x $$\n",
    "\n",
    "We can estimate the coefficients as follows:\n",
    "$$ \n",
    "b_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\mu_x )(y_i - \\mu_y)}{\\sum^{n}_{i=1} (x_i - \\mu_x )^2} \n",
    "= \\frac{covariance(x, y)}{variance(x)}\n",
    "$$\n",
    "$$\n",
    "b_0 = \\mu_y - b_1 \\mu_x \n",
    "= mean(y) - b_1 * mean(x)\n",
    "$$\n",
    "\n",
    "\n",
    "* Mean       : $$ \\mu_x = \\frac{1}{n} \\sum^{n}_{i=1} x_i $$\n",
    "* Variance   : $$ \\sum_{i=1}^{n} (x_i - \\mu_x)^2 $$\n",
    "* Covariance : Generalization of correlation to describe the relation between two or more values.\n",
    "$$ \\sum^{n}_{i=1} (x_i - \\mu_x)(y_i - \\mu_y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(values):\n",
    "    return sum(values) / float(len(values))\n",
    "\n",
    "def variance(values):\n",
    "    mean_val = mean(values)\n",
    "    variance = [ (val - mean_val)**2.0 for val in values ]\n",
    "    return sum(variance)\n",
    "\n",
    "def covariance(x, y):\n",
    "    mean_x = mean(x)\n",
    "    mean_y = mean(y)\n",
    "    covar = 0.0\n",
    "    for i in range(len(x)):\n",
    "        covar += (x[i]-mean_x) * (y[i]-mean_y)\n",
    "    return covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x stats: mean=3.000 variance=10.000\n",
      "y stats: mean=2.800 variance=8.800\n",
      "Covariance: 8.000 \n"
     ]
    }
   ],
   "source": [
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]                              \n",
    "x = [row[0] for row in dataset]                                                 \n",
    "y = [row[1] for row in dataset]                                                 \n",
    "mean_x, mean_y = mean(x), mean(y)                                               \n",
    "var_x, var_y = variance(x), variance(y)                         \n",
    "print('x stats: mean=%.3f variance=%.3f' % (mean_x, var_x))                     \n",
    "print('y stats: mean=%.3f variance=%.3f' % (mean_y, var_y))\n",
    "\n",
    "covar = covariance(x, y)\n",
    "print( 'Covariance: %.3f ' % (covar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coefficients(dataset):\n",
    "    x = [row[0] for row in dataset]\n",
    "    y = [row[1] for row in dataset]\n",
    "    x_mean, y_mean = mean(x), mean(y)\n",
    "    b1 = covariance(x, y) / variance(x)\n",
    "    b0 = y_mean - b1*x_mean\n",
    "    return b0, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Coefficients: B0=0.400, B1=0.800\n"
     ]
    }
   ],
   "source": [
    "b0, b1 = coefficients(dataset)\n",
    "print( ' Coefficients: B0={:.3f}, B1={:.3f}'.format(b0, b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_linear_regression(train, test):\n",
    "    predictions = []\n",
    "    b0, b1 = coefficients(train)\n",
    "    for row in test:\n",
    "        yhat = b0 + b1*row[0]\n",
    "        predictions.append( yhat )\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Getting_Started import rmse_metric\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm):\n",
    "    test_set = []\n",
    "    for row in dataset:\n",
    "        row_copy = list(row)\n",
    "        row_copy[-1] = None\n",
    "        test_set.append(row_copy)\n",
    "    predicted = algorithm(dataset, test_set)\n",
    "    print(predicted)\n",
    "    actual = [row[-1] for row in dataset]\n",
    "    rmse = rmse_metric(actual, predicted)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1999999999999995, 1.9999999999999996, 3.5999999999999996, 2.8, 4.3999999999999995]\n",
      " RMSE: 0.693 \n"
     ]
    }
   ],
   "source": [
    "rmse = evaluate_algorithm(dataset, simple_linear_regression)\n",
    "print( ' RMSE: %.3f ' % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a vector of inputs $X^T = (X_1, ..., X_p)$, $X$ being a column vector, one can predict the output of $Y$ by using the following model:\n",
    "$$\n",
    "\\hat{Y} = \\hat{\\beta_0} + \\sum^{p}_{j=1} X_j \\hat{\\beta_j}\n",
    "$$\n",
    "$p$ is the number of features.\n",
    "$\\hat{\\beta_0}$ is the intercept or **bias** term.\n",
    "\n",
    "We can include the constant variable 1 in $X$ in order to include $\\hat{\\beta_0}$ with the vector of coefficients $\\hat{\\beta}$ so that our linear model can be writen as an inner product,\n",
    "$$\n",
    "\\hat{Y} = X^T \\hat{\\beta}\n",
    "$$\n",
    "\n",
    "We can interpret our model as a function over a $p$-dimensional input space, $f(X) = X^T \\hat{\\beta}$ with its gradient $f\\prime (X) = \\hat{\\beta} $.\n",
    "$\\beta$ (we are dropping the hat) is thus a vector in input space that points in the steepest uphill direction.\n",
    "\n",
    "To fit the linear model to a dataset we will use the method of least squares.\n",
    "We pick the coefficients $\\beta$ that **minimize the residual sum of squares**\n",
    "$$\n",
    "RSS(\\beta ) =\\sum^{N}_{i=1} (y_i - x_{i}^{T}\\beta )^2\n",
    "$$\n",
    "\n",
    "In matrix notation,\n",
    "$$\n",
    "RSS(\\beta ) = (\\mathbf{y - X}\\beta)^T (\\mathbf{y - X}\\beta),\n",
    "$$\n",
    "$\\mathbf{X}$ is an $N \\times p$ matrix where each row corresponds to an input vector, and $\\mathbf{y}$ is a $N$-vector of outputs for the training set.\n",
    "Because the RSS is a quadratic function its minimum always exists, although it may not be unique.\n",
    "\n",
    "In order to continue, let's differentiate $RSS(\\beta )$ with respect to $\\beta$. This will give us the set of equations,\n",
    "$$\n",
    "\\mathbf{X}^T (\\mathbf{y-X}\\beta) = 0\n",
    "$$\n",
    "\n",
    "In the case that $\\mathbf{X}^T \\mathbf{X}$ is nonsingular, we then obtain \n",
    "$$\n",
    "\\hat{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
