{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let the velocity be the previous weight change\n",
    "\n",
    "$$v(t-1) = \\Delta w(t-1)$$\n",
    "or\n",
    "$$v(t) = \\mu v(t-1) - \\eta \\nabla J(t)$$\n",
    "\n",
    "* Update weights\n",
    "\n",
    "$$\\Delta w(t) = \\mu v(t-1) - \\eta \\nabla J(t)$$\n",
    "or\n",
    "$$\\Delta w(t) = -\\mu v(t-1) + (1+\\mu)v(t) $$\n",
    "\n",
    "```\n",
    "v = dw\n",
    "dw = momentum * v - learning_rate * gradient_cost\n",
    "w += dw\n",
    "```\n",
    "\n",
    "For Nesterov momentum\n",
    "```\n",
    "w_ahead = w + momentum * v\n",
    "dw = momentum * v - learning_rate * cost_gradient(w_ahead)\n",
    "w += dw\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Momentum\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum\n",
    "\n",
    "Classical moentum is a technique for accelerating gradient descent that accumulates a velocity vector in the directions of persistent reduction in the objective across iterations.\n",
    "Given an objective function $f(\\theta )$, classical momentum is given by:\n",
    "$$ v_{t+1} = \\mu v_t - \\epsilon \\nabla f(\\theta_t )$$\n",
    "$$ \\theta_{t+1} = \\theta_t + v_{t+1}$$\n",
    "\n",
    "where $\\epsilon > 0$ is the learning rate, $\\mu \\in [0,1]$ is the momentum coeficient, and $\\nabla f(\\theta_t )$ is the gradient at $\\theta_t$. \n",
    "\n",
    "Based on the Heavy ball method (Polyak 1964). The iterations of gradient descent tend to bounce between the walls of narrow valleys - objective surface. \n",
    "To avoid bouncing from wall to wall we add a momentum term to the gradient step. This term nudges the next iteration ($W$) in the direction of the previous steps.\n",
    "\n",
    "$$ x^{n+1} = x^n - \\alpha P(x^n) + \\beta (x^n - x^{n-1})$$\n",
    "\n",
    "modify the velocity of the point in weight space.\n",
    "\n",
    "# Nesterov Momentum\n",
    "\n",
    "* [Nesterov's Accelerated Gradient Descent](https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/)\n",
    "* [Revisiting Nesterov's Acceleration](https://blogs.princeton.edu/imabandit/2015/06/30/revisiting-nesterovs-acceleration/)\n",
    "\n",
    "$$ v_{t+1} = \\mu v_t - \\epsilon \\nabla f(\\theta_t + \\mu v_t ) $$\n",
    "$$ \\theta_{t+1} = \\theta_t + v_{t+1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def y2indicator(Y, K=10):\n",
    "    # K=10 for MNIST\n",
    "    # Python\n",
    "    N = len(Y)\n",
    "    Y = Y.astype(np.int32)\n",
    "    ind = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        ind[i, Y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "def py_y2indicator(Y, K=10):\n",
    "    N = len(Y)\n",
    "    Y = Y.astype(np.int32)\n",
    "    ind = np.zeros((N, K))\n",
    "    ind[np.arange(N), Y] = 1\n",
    "    return ind\n",
    "    \n",
    "def sk_y2indicator(Y, K=10):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(Y.max()+1))\n",
    "    return lb.transform(Y)\n",
    "    \n",
    "def get_normalized_data():\n",
    "    df = pd.read_csv('../datasets/mnist/train.csv')\n",
    "    data = df.as_matrix().astype(np.float32)\n",
    "    np.random.shuffle(data)\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    mu = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    np.place(std, std==0, 1)\n",
    "    X = (X-mu)/std\n",
    "    return X, Y\n",
    "\n",
    "def error(p_y, T):\n",
    "    predictions = np.argmax(p_y, axis=1)\n",
    "    return np.mean(predictions != T)\n",
    "\n",
    "def cost(p_y, T):\n",
    "    total = T * np.log(p_y)\n",
    "    return -total.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = np.sqrt(in_dim/2.0)\n",
    "    return np.random.randn(size[0],size[1]) / xavier_stddev\n",
    "\n",
    "def derivative_W2(Z, T, Y):\n",
    "    return Z.T.dot(Y-T)\n",
    "                   \n",
    "def derivative_b2(T, Y):\n",
    "    return (Y-T).sum(axis=0)\n",
    "\n",
    "def derivative_W1(X, Z, T, Y, W2):\n",
    "    #return X.T.dot( ((Y-T).dot(W2.T) * Z * (1-Z)) )  # for sigmoid\n",
    "    return X.T.dot( ((Y-T).dot(W2.T) * (Z>0)) ) # for relu\n",
    "\n",
    "def derivative_b1(Z, T, Y, W2):\n",
    "    #return ( (Y-T).dot(W2.T) * (Z*(1-Z)) ).sum(axis=0) # for sigmoid      \n",
    "    return ( (Y-Y).dot(W2.T) * (Z>0) ).sum(axis=0) # for relu\n",
    "\n",
    "def relu(a):   \n",
    "    a[a<0] = 0\n",
    "    return a\n",
    "\n",
    "def sigmoid(a):\n",
    "    return 1.0 / (1.0 + np.exp(-a))\n",
    "    \n",
    "def softmax(a):                                                                 \n",
    "    expA = np.exp(a)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)\n",
    "\n",
    "def forward(X, W1, b1, W2, b2):\n",
    "    # Z = 1 / (1 + np.exp(-(X.dot(W1)+b1)))\n",
    "    Z = relu( X.dot(W1)+b1 )\n",
    "    Y = softmax( Z.dot(W2)+b2 )\n",
    "    return Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "X, Y = get_normalized_data()\n",
    "Xtrain = X[:-1000,]                                                         \n",
    "Ytrain = Y[:-1000]                                                          \n",
    "Xtest  = X[-1000:,]                                                         \n",
    "Ytest  = Y[-1000:]                                                          \n",
    "Ytrain_ind = y2indicator(Ytrain)                                            \n",
    "Ytest_ind = y2indicator(Ytest)\n",
    "\n",
    "# Parameters\n",
    "lr = 1.0e-5\n",
    "reg = 1.0e-2\n",
    "N, D = Xtrain.shape\n",
    "\n",
    "M = 300\n",
    "K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "print_period = 10\n",
    "batch_size = 500\n",
    "n_batches = N//batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 1228.0390494036546\n",
      "Error:0.368\n",
      "Cost: 399.59675066997426\n",
      "Error:0.116\n",
      "Cost: 316.4176767076559\n",
      "Error:0.094\n",
      "Cost: 277.90041155790874\n",
      "Error:0.083\n",
      "Cost: 252.9905093728027\n",
      "Error:0.077\n",
      "Cost: 235.09130905805173\n",
      "Error:0.07\n",
      "Cost: 221.29664099202722\n",
      "Error:0.063\n",
      "Cost: 210.23843997930842\n",
      "Error:0.058\n",
      "Cost: 200.923602949563\n",
      "Error:0.058\n",
      "Cost: 192.86928974887724\n",
      "Error:0.058\n",
      "Final error: 0.056\n"
     ]
    }
   ],
   "source": [
    "W1 = xavier_init([D, M])\n",
    "b1 = np.zeros(M)\n",
    "W2 = xavier_init([M, K])\n",
    "b2 = np.zeros(K)\n",
    "\n",
    "LL_batch = []\n",
    "ER_batch = []\n",
    "for i in range(max_iter):\n",
    "    for j in range(n_batches):\n",
    "        batch_range = (j*batch_size, j*batch_size + batch_size)\n",
    "        \n",
    "        Xbatch = Xtrain[batch_range[0]:batch_range[1], ]                \n",
    "        Ybatch = Ytrain_ind[batch_range[0]:batch_range[1], ]            \n",
    "        pYbatch, Z = forward(Xbatch, W1, b1, W2, b2)                                         \n",
    "                                                                                \n",
    "        # updates                                                           \n",
    "        W2 -= lr*(derivative_W2(Z, Ybatch, pYbatch) + reg*W2)               \n",
    "        b2 -= lr*(derivative_b2(Ybatch, pYbatch)    + reg*b2)                  \n",
    "        W1 -= lr*(derivative_W1(Xbatch, Z, Ybatch, pYbatch, W2) + reg*W1)   \n",
    "        b1 -= lr*(derivative_b1(Z, Ybatch, pYbatch, W2)         + reg*b1)           \n",
    "                                                                                \n",
    "    if i % print_period==0:                                           \n",
    "        # calculate just for LL                                         \n",
    "        pY, _ = forward(Xtest, W1, b1, W2, b2)                \n",
    "        LL_batch.append( cost(pY, Ytest_ind) )                                 \n",
    "        ER_batch.append( error(pY, Ytest) )\n",
    "        print(\"Cost: {}\".format(LL_batch[-1]))                                \n",
    "        print(\"Error:{}\".format(ER_batch[-1]))                                        \n",
    "                                                                                \n",
    "pY, _ = forward(Xtest, W1, b1, W2, b2)                                      \n",
    "print(\"Final error: {}\".format(error(pY, Ytest)))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch with momentum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 421.7639542504308\n",
      "Error rate: 0.123\n",
      "Cost: 177.40917302427528\n",
      "Error rate: 0.055\n",
      "Cost: 139.80480845623214\n",
      "Error rate: 0.039\n",
      "Cost: 122.17314637185196\n",
      "Error rate: 0.032\n",
      "Cost: 112.37396819291772\n",
      "Error rate: 0.03\n",
      "Cost: 106.11588400452838\n",
      "Error rate: 0.028\n",
      "Cost: 101.70248513248745\n",
      "Error rate: 0.027\n",
      "Cost: 98.5325190817444\n",
      "Error rate: 0.025\n",
      "Cost: 96.31443683853391\n",
      "Error rate: 0.024\n",
      "Cost: 94.70365294367467\n",
      "Error rate: 0.024\n",
      "Final error rate: 0.023\n"
     ]
    }
   ],
   "source": [
    "W1 = xavier_init([D, M])\n",
    "b1 = np.zeros(M)\n",
    "W2 = xavier_init([M, K])\n",
    "b2 = np.zeros(K)                                              \n",
    "\n",
    "LL_momentum = []                                                            \n",
    "CR_momentum = []                                                            \n",
    "mu = 0.9                                                                    \n",
    "dW2 = 0                                                                     \n",
    "db2 = 0                                                                     \n",
    "dW1 = 0                                                                     \n",
    "db1 = 0                                                                     \n",
    "for i in range(max_iter):                                                  \n",
    "    for j in range(n_batches):                                             \n",
    "        batch_range = (j*batch_size, j*batch_size + batch_size)\n",
    "        \n",
    "        Xbatch = Xtrain[batch_range[0]:batch_range[1], ]                \n",
    "        Ybatch = Ytrain_ind[batch_range[0]:batch_range[1], ]            \n",
    "        pYbatch, Z = forward(Xbatch, W1, b1, W2, b2)                        \n",
    "                                                                                \n",
    "        # updates                                                           \n",
    "        dW2 = mu*dW2 - lr*(derivative_W2(Z, Ybatch, pYbatch) + reg*W2)      \n",
    "        W2 += dW2                                                           \n",
    "        db2 = mu*db2 - lr*(derivative_b2(Ybatch, pYbatch) + reg*b2)         \n",
    "        b2 += db2                                                           \n",
    "        dW1 = mu*dW1 - lr*(derivative_W1(Xbatch, Z, Ybatch, pYbatch, W2) + reg*W1)\n",
    "        W1 += dW1                                                           \n",
    "        db1 = mu*db1 - lr*(derivative_b1(Z, Ybatch, pYbatch, W2) + reg*b1)  \n",
    "        b1 += db1                                                           \n",
    "                                                                                \n",
    "    if i % print_period == 0:                                           \n",
    "        pY, _ = forward(Xtest, W1, b1, W2, b2)           \n",
    "        ll = cost(pY, Ytest_ind)\n",
    "        LL_momentum.append(ll)\n",
    "        err = error(pY, Ytest)\n",
    "        CR_momentum.append(err)\n",
    "        print(\"Cost: {}\".format(ll))\n",
    "        print(\"Error rate: {}\".format(err))\n",
    "pY, _ = forward(Xtest, W1, b1, W2, b2)\n",
    "print(\"Final error rate: {}\".format(error(pY, Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch with Nesterov momentum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 93.60682759578333\n",
      "Error rate: 0.024\n",
      "Cost: 92.87573365914639\n",
      "Error rate: 0.022\n",
      "Cost: 92.45457237983254\n",
      "Error rate: 0.022\n",
      "Cost: 92.25178530041181\n",
      "Error rate: 0.022\n",
      "Cost: 92.1808365815572\n",
      "Error rate: 0.022\n",
      "Cost: 92.19702635954651\n",
      "Error rate: 0.022\n",
      "Cost: 92.33979991889042\n",
      "Error rate: 0.022\n",
      "Cost: 92.5093714968576\n",
      "Error rate: 0.022\n",
      "Cost: 92.72574718375051\n",
      "Error rate: 0.022\n",
      "Cost: 92.97895888313325\n",
      "Error rate: 0.022\n",
      "Final error: 0.022\n"
     ]
    }
   ],
   "source": [
    "LL_nest = []                                                                \n",
    "CR_nest = []                                                                \n",
    "mu = 0.9                                                                    \n",
    "# alternate version uses dW                                                 \n",
    "# dW2 = 0                                                                   \n",
    "# db2 = 0                                                                   \n",
    "# dW1 = 0                                                                   \n",
    "# db1 = 0                                                                   \n",
    "vW2 = 0                                                                     \n",
    "vb2 = 0                                                                     \n",
    "vW1 = 0                                                                     \n",
    "vb1 = 0                                                                     \n",
    "for i in range(max_iter):                                                  \n",
    "    for j in range(n_batches):                                             \n",
    "        # because we want g(t) = grad(f(W(t-1) - lr*mu*dW(t-1)))            \n",
    "        # dW(t) = mu*dW(t-1) + g(t)                                         \n",
    "        # W(t) = W(t-1) - mu*dW(t)                                          \n",
    "        W1_tmp = W1 - lr*mu*vW1                                             \n",
    "        b1_tmp = b1 - lr*mu*vb1                                             \n",
    "        W2_tmp = W2 - lr*mu*vW2                                             \n",
    "        b2_tmp = b2 - lr*mu*vb2                                             \n",
    "           \n",
    "        batch_range = (j*batch_size, j*batch_size + batch_size)\n",
    "        \n",
    "        Xbatch = Xtrain[batch_range[0]:batch_range[1], ]                \n",
    "        Ybatch = Ytrain_ind[batch_range[0]:batch_range[1], ]            \n",
    "        pYbatch, Z = forward(Xbatch, W1, b1, W2, b2) \n",
    "        \n",
    "        # pYbatch, Z = forward(Xbatch, W1, b1, W2, b2)                      \n",
    "        pYbatch, Z = forward(Xbatch, W1_tmp, b1_tmp, W2_tmp, b2_tmp)        \n",
    "                                                                                \n",
    "        # updates                                                           \n",
    "        # dW2 = mu*mu*dW2 - (1 + mu)*lr*(derivative_w2(Z, Ybatch, pYbatch) + reg*W2)\n",
    "        # W2 += dW2                                                         \n",
    "        # db2 = mu*mu*db2 - (1 + mu)*lr*(derivative_b2(Ybatch, pYbatch) + reg*b2)\n",
    "        # b2 += db2                                                         \n",
    "        # dW1 = mu*mu*dW1 - (1 + mu)*lr*(derivative_w1(Xbatch, Z, Ybatch, pYbatch, W2) + reg*W1)\n",
    "        # W1 += dW1                                                         \n",
    "        # db1 = mu*mu*db1 - (1 + mu)*lr*(derivative_b1(Z, Ybatch, pYbatch, W2) + reg*b1)\n",
    "        # b1 += db1                                                         \n",
    "        vW2 = mu*vW2 + derivative_W2(Z, Ybatch, pYbatch) + reg*W2_tmp       \n",
    "        W2 -= lr*vW2                                                        \n",
    "        vb2 = mu*vb2 + derivative_b2(Ybatch, pYbatch) + reg*b2_tmp          \n",
    "        b2 -= lr*vb2                                                        \n",
    "        vW1 = mu*vW1 + derivative_W1(Xbatch, Z, Ybatch, pYbatch, W2_tmp) + reg*W1_tmp\n",
    "        W1 -= lr*vW1                                                        \n",
    "        vb1 = mu*vb1 + derivative_b1(Z, Ybatch, pYbatch, W2_tmp) + reg*b1_tmp\n",
    "        b1 -= lr*vb1\n",
    "        \n",
    "    if i % print_period == 0:                                           \n",
    "        # calculate just for LL                                         \n",
    "        pY, _ = forward(Xtest, W1, b1, W2, b2)                          \n",
    "        # print \"pY:\", pY                                               \n",
    "        ll = cost(pY, Ytest_ind)                                        \n",
    "        LL_nest.append(ll)                                              \n",
    "        print(\"Cost: {}\".format(ll))                                                                               \n",
    "        err = error(pY, Ytest)                                     \n",
    "        CR_nest.append(err)                                             \n",
    "        print(\"Error rate: {}\".format(err))                                        \n",
    "pY, _ = forward(Xtest, W1, b1, W2, b2)                                      \n",
    "print(\"Final error: {}\".format(error(pY, Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f356883bdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LL_batch, label=\"batch\")                                           \n",
    "plt.plot(LL_momentum, label=\"momentum\")                                     \n",
    "plt.plot(LL_nest, label=\"nesterov\")                                         \n",
    "plt.legend()                                                                \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
