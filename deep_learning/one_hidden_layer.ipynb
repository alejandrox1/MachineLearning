{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X the features can be considered as input from other neurons.\n",
    "\n",
    "A given neuron will then output a signal which is a combination of the inputs, weighted by the strenght of \n",
    "those input neurons to this output neuron.\n",
    "\n",
    "$$ y = sigmoid (w_1 * x_1 + w_2 *x_2 + ... + w_n * x_n) $$\n",
    "\n",
    "We ignore the bias term since it can readily be incoporated by adding an extra dimension, $x_0$, which is always 1.\n",
    "\n",
    "You can interpret the output as a probability, $P(y=1 | x, \\theta) $, which will be used interchangibly with $y$.\n",
    "\n",
    "\n",
    "A very positive weight would be a excitatory connection, a very negative weight an inhibitory conection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Action\n",
    "\n",
    "Suppose we have a 1-hidden layer neural net:\n",
    "$x$ is the input, $z$ is the hidden layer, and $y$ is the output layer.\n",
    "\n",
    "$$z_1 = s(w_{11}*x_1 + w_{12}*x_2 )$$\n",
    "$$z_2 = s(w_{21}*x_1 + w_{22}*x_2 )$$\n",
    "\n",
    "Where $s$ is any non-linear function.\n",
    "The three most common choices are:\n",
    "* Sigmoid\n",
    "* Hyperbolic tangent - Scaled version of the sigmoid function as it is centered around 0.\n",
    "* Rectifier linear unit (ReLU)\n",
    " * ```\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y$ can be computed as\n",
    "\n",
    "$$y = s\\prime (v_1 *z_1 + v_2 *z_2)$$\n",
    "\n",
    "Where $s\\prime$ is either a `sigmoid` or a `softmax`.\n",
    "\n",
    "Note that inside the `sigmoid` functions we simply have the dot product between the input and the weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def y2indicator(y, K):\n",
    "    '''Transfor Y into an indicator matrix\n",
    "    The indicator matrix will be an NxK matrix.\n",
    "    \n",
    "    N : number of samples\n",
    "    K : number of classes in the output\n",
    "    '''\n",
    "    N = len(y)\n",
    "    ind = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/train.csv')\n",
    "Y = X['label'].values\n",
    "T = X['label'].values\n",
    "X = X.drop('label', axis=1)\n",
    "X = X.values\n",
    "\n",
    "# Number of Features (dimensionality of each input)\n",
    "D = X.shape[1]\n",
    "# Number of classes\n",
    "K = len(np.unique(T))\n",
    "# Number of hiden units\n",
    "M = 300\n",
    "\n",
    "T = y2indicator(Y, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions and Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_rate(Y, P):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    for i in range(len(Y)):\n",
    "        n_total += 1\n",
    "        if Y[i]==P[i]:\n",
    "            n_correct += 1\n",
    "    return float(n_correct)/n_total\n",
    "\n",
    "def relu(x):\n",
    "    '''Rectified Linear Unit'''\n",
    "    return x * (x>0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "def softmax(X):\n",
    "    ''' exp(x[k]) / [exp(x[1]) +...+ exp(x[K])]'''\n",
    "    expX = np.exp(X)\n",
    "    return expX / np.sum(expX, axis=1,keepdims=True)\n",
    "\n",
    "def forward(X, W1, W2, b1, b2):\n",
    "    ''' O--W--O--V--O\n",
    "        X    Z      Y\n",
    "    '''\n",
    "    #Z = relu(X.dot(W1) + b1)\n",
    "    Z = sigmoid(X.dot(W1) + b1)\n",
    "    Y = softmax(Z.dot(W2) + b2)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Weights\n",
    "W1 = np.random.randn(D,M)\n",
    "# bias for first layer\n",
    "b1 = np.random.randn(M)\n",
    "W2 = np.random.randn(M, K)\n",
    "# bias for second layer\n",
    "b2 = np.random.randn(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification rate for randomly chosen weights: 0.10757142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alarcj/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "P_Y_given_X = forward(X, W1, W2, b1, b2)\n",
    "\n",
    "# Predict\n",
    "P = np.argmax(P_Y_given_X, axis=1)\n",
    "assert(len(Y) == len(T))\n",
    "print(\"Classification rate for randomly chosen weights:\", classification_rate(Y, P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function\n",
    "\n",
    "Optimize it via Gradient Descent.\n",
    "We travel along the graident of our cost function with respect to $W$ and $V$ until we hit a minimum.\n",
    "\n",
    "```\n",
    "J = - sum[n=1,...,N]( sum[k=1,...,K]( T[n,k] * logY[n,k] ) )\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(T, Y):\n",
    "    return (T*np.log(Y)).sum()\n",
    "\n",
    "def derivative_W2(Z, T, Y):\n",
    "    return Z.T.dot(T-Y)\n",
    "\n",
    "def derivative_W1(X, Z, T, Y, W2):\n",
    "    dZ = (T-Y).dot(W2.T) * Z * (1-Z)\n",
    "    return X.T.dot(dZ)\n",
    "\n",
    "def derivative_b2(T, Y):\n",
    "    return (T-Y).sum(axis=0)\n",
    "\n",
    "def derivative_b1(T, Y, W2, Z):\n",
    "    return ((T-Y).dot(W2.T) * Z * (1-Z)).sum(axis=0)\n",
    "\n",
    "def forward(X, W1, b1, W2, b2):\n",
    "    ''' O--W--O--V--O\n",
    "        X    Z      Y\n",
    "    '''\n",
    "    #Z = relu(X.dot(W1) + b1)\n",
    "    Z = sigmoid(X.dot(W1) + b1)\n",
    "    Y = softmax(Z.dot(W2) + b2)\n",
    "    return Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alarcj/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: -713226.1771666248. classification rate: 0.10757142857142857\n",
      "\n",
      "epoch: 100 cost: -301205.13705253135. classification rate: 0.2399047619047619\n",
      "\n",
      "epoch: 200 cost: -218712.00976892738. classification rate: 0.35264285714285715\n",
      "\n",
      "epoch: 300 cost: -176711.77176909734. classification rate: 0.43033333333333335\n",
      "\n",
      "epoch: 400 cost: -151251.24687362034. classification rate: 0.48892857142857143\n",
      "\n",
      "epoch: 500 cost: -134371.1428855521. classification rate: 0.531\n",
      "\n",
      "epoch: 600 cost: -122113.92323055952. classification rate: 0.5624047619047619\n",
      "\n",
      "epoch: 700 cost: -112737.05279013839. classification rate: 0.5874761904761905\n",
      "\n",
      "epoch: 800 cost: -105207.41868502738. classification rate: 0.6095238095238096\n",
      "\n",
      "epoch: 900 cost: -99057.68623203434. classification rate: 0.6269285714285714\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD8CAYAAABU4IIeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e12c24a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "epoch_rate = 100\n",
    "learning_rate = 10e-7\n",
    "costs = []\n",
    "for epoch in range(epochs):\n",
    "    output, hidden = forward(X, W1, b1, W2, b2)\n",
    "    if epoch % epoch_rate == 0:\n",
    "        c = cost(T, output)\n",
    "        P = np.argmax(output, axis=1)\n",
    "        r = classification_rate(Y, P)\n",
    "        print('epoch: {} cost: {}. classification rate: {}\\n'.format(epoch, c, r))\n",
    "        costs.append(c)\n",
    "        \n",
    "    W2 += learning_rate * derivative_W2(hidden, T, output)\n",
    "    b2 += learning_rate * derivative_b2(T, output)\n",
    "    W1 += learning_rate * derivative_W1(X, hidden, T, output, W2)\n",
    "    b1 += learning_rate * derivative_b1(T, output, W2, hidden)\n",
    "    \n",
    "plt.plot(costs)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
